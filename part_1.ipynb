{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7084ab6-cfbc-49da-be87-ded7ddb97c24",
   "metadata": {},
   "source": [
    "# Data Visualization and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a1ef517-2eb2-4fa7-93fd-107d3154a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ef1d7d3-d275-4a32-bff0-a3642190a35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75255, 2)\n",
      "              Datetime  Power_MWH\n",
      "0  2010-01-01 00:00:00    31647.0\n",
      "1  2010-12-31 01:00:00    29634.0\n",
      "2  2010-12-31 02:00:00    28614.0\n",
      "3  2010-12-31 03:00:00    28146.0\n",
      "4  2010-12-31 04:00:00    28051.0\n"
     ]
    }
   ],
   "source": [
    "# Read the data into a pandas DataFrame\n",
    "df = pd.read_csv('power_data.csv')[[\"Datetime\", \"Power_MWH\"]]\n",
    "\n",
    "# Check the shape and head of the data\n",
    "print(df.shape)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e05d016-fb87-4b52-852a-11099d672191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datetime     0\n",
      "Power_MWH    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6abc24d-0f0a-495b-90bd-7f6b90ffb880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datetime      object\n",
      "Power_MWH    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the data types of the columns\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9679323-a239-4e0f-8d21-874fe355e067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Power_MWH\n",
      "count  75255.000000\n",
      "mean   31729.893575\n",
      "std     6503.002099\n",
      "min    14544.000000\n",
      "25%    27233.500000\n",
      "50%    30838.000000\n",
      "75%    35353.500000\n",
      "max    61646.000000\n"
     ]
    }
   ],
   "source": [
    "# Get a basic understanding of the distribution of the data\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b1a0a2d-457f-4f9c-82f4-174e48b97dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert date_and_time column to datetime format\n",
    "df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "df.set_index('Datetime', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcb1603-aa05-4267-b298-52dd8f0ca51e",
   "metadata": {},
   "source": [
    "## Issues with Data \n",
    "\n",
    "There are several issues that can arise when working with the energy consumption data that makes this problem challenging. Here are a few examples:\n",
    "\n",
    "\n",
    "Outliers: The data may contain outliers, which can have a significant effect on the performance of the model. Outliers can be detected using various methods such as visualization, Z-score, and IQR. Once detected, outliers should be treated or removed.\n",
    "\n",
    "Seasonality: The energy consumption data may show seasonality, which can make it difficult to make predictions. Seasonality can be addressed by using time series models that are specifically designed to handle seasonal data such as seasonal decomposition of time series and seasonal ARIMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b3a137-2c02-4587-a823-44772cd12b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Power_MWH\n",
      "Datetime                      \n",
      "2010-09-02 13:00:00    51755.0\n",
      "2010-09-02 14:00:00    53882.0\n",
      "2010-09-02 15:00:00    55188.0\n",
      "2010-09-02 16:00:00    56015.0\n",
      "2010-09-02 17:00:00    56336.0\n",
      "...                        ...\n",
      "2018-07-01 19:00:00    51437.0\n",
      "2018-06-18 16:00:00    51818.0\n",
      "2018-06-18 17:00:00    52558.0\n",
      "2018-06-18 18:00:00    52213.0\n",
      "2018-06-18 19:00:00    51597.0\n",
      "\n",
      "[726 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# check for outlier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# calculate z-scores\n",
    "z_scores = (df['Power_MWH'] - df['Power_MWH'].mean()) / df['Power_MWH'].std()\n",
    "\n",
    "# identify outliers\n",
    "outliers = df[np.abs(z_scores) > 3]\n",
    "\n",
    "# display outliers\n",
    "print(outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b7c4957-4914-4505-b087-f7e852cf85f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the outlier values with the mean\n",
    "df = df.copy()\n",
    "df.loc[np.abs(z_scores) > 3, 'Power_MWH'] = df['Power_MWH'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbec20f1-9f65-4a47-8e99-ee2fcb983ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datetime\n",
       "2010-01-01 00:00:00    1.023422\n",
       "2010-12-31 01:00:00    1.030913\n",
       "2010-12-31 02:00:00    1.028135\n",
       "2010-12-31 03:00:00    1.017176\n",
       "2010-12-31 04:00:00    1.003614\n",
       "                         ...   \n",
       "2018-01-01 20:00:00    0.994013\n",
       "2018-01-01 21:00:00    1.010734\n",
       "2018-01-01 22:00:00    1.023422\n",
       "2018-01-01 23:00:00    1.030913\n",
       "2018-01-02 00:00:00    1.028135\n",
       "Name: seasonal, Length: 75255, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test for seasonality\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "result = seasonal_decompose(df['Power_MWH'], model='multiplicative', period=12)\n",
    "\n",
    "\n",
    "# plot the seasonal component\n",
    "plt.figure(figsize=(12,6))\n",
    "result.seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67105677-50f7-4ae1-9b23-7b26499ae475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9321e8-555b-42ae-b9a6-3bbb1d415143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victorfrancis/opt/miniconda3/lib/python3.9/site-packages/statsmodels/compat/pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n",
      "/Users/victorfrancis/opt/miniconda3/lib/python3.9/site-packages/statsmodels/graphics/tsaplots.py:348: FutureWarning: The default method 'yw' can produce PACF values outside of the [-1,1] interval. After 0.13, the default will change tounadjusted Yule-Walker ('ywm'). You can use this method now by setting method='ywm'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# test for seasonality\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "plot_acf(df['Power_MWH'], lags=24*7)\n",
    "plot_pacf(df['Power_MWH'], lags=24*7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bbde04-044e-47d6-bee5-6ff397e136ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data using line plots\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(df['Power_MWH'])\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Energy Consumption (MWH)')\n",
    "plt.title('Hourly Energy Consumption over the Years')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a54287-38d0-456a-9330-9e084be74a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffc0e86-5c47-41eb-a896-95bbb45048ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6579338d-9836-4d99-bfe6-08452c41da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the distribution of the data using histograms\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.histplot(df['Power_MWH'], kde=True)\n",
    "plt.xlabel('Energy Consumption (MWH)')\n",
    "plt.title('Distribution of Energy Consumption')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14182e34-6cf7-4af2-97ee-d8874d3e6bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot energy consumption for each hour\n",
    "plt.figure(figsize=(12,6))\n",
    "df.groupby(df.index.hour)['Power_MWH'].mean().plot(kind='bar')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Energy Consumption (MWH)')\n",
    "plt.title('Energy Consumption by Hour')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a74d336-b0ab-4618-ae94-7581c381019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plot energy consumption for each day of the week\n",
    "plt.figure(figsize=(12,6))\n",
    "df.groupby(df.index.dayofweek)['Power_MWH'].mean().plot(kind='bar')\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.ylabel('Energy Consumption (MWH)')\n",
    "plt.title('Energy Consumption by Day of the Week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121d3023-e4f4-44fb-b604-a0519defcaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plot energy consumption for each month\n",
    "plt.figure(figsize=(12,6))\n",
    "df.groupby(df.index.month)['Power_MWH'].mean().plot(kind='bar')\n",
    "plt.xlabel('Month of the Year')\n",
    "plt.ylabel('Energy Consumption (MWH)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49317c68-34c3-44c5-ae5d-2b643ddc5c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4886abc5-602c-4600-a6f1-a49fecddac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for stationarity using the Augmented Dickey-Fuller test\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "result = adfuller(df['Power_MWH'])\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93e35c4-a0c2-4057-a777-14cf2125b242",
   "metadata": {},
   "source": [
    "The ADF test result suggests that the data is stationary.\n",
    "\n",
    "The ADF statistic is a test statistic that is used to decide whether the null hypothesis (that the time series is not stationary) can be rejected. The p-value is the probability of obtaining a test statistic as extreme as the one observed, assuming the null hypothesis is true.\n",
    "\n",
    "Here, the ADF statistic is -14.158963 and the p-value is 0.000000. Since the p-value is less than the threshold of 0.05, it means that we can reject the null hypothesis and conclude that the data is stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6eae73-50e8-454a-b0ff-2254aac7467d",
   "metadata": {},
   "source": [
    "## Issues with Data \n",
    "\n",
    "There are several issues that can arise when working with the energy consumption data that makes this problem challenging. Here are a few examples:\n",
    "\n",
    "\n",
    "Outliers: The data may contain outliers, which can have a significant effect on the performance of the model. Outliers can be detected using various methods such as visualization, Z-score, and IQR. Once detected, outliers should be treated or removed.\n",
    "\n",
    "Seasonality: The energy consumption data show some seasonality, which can make it difficult to make predictions. Seasonality can be addressed by using time series models that are specifically designed to handle seasonal data such as seasonal decomposition of time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f3205f-2ac9-424e-8516-42971473843c",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e673bd3a",
   "metadata": {},
   "source": [
    "## New features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93e661",
   "metadata": {},
   "source": [
    "- **Hour of the day**: The hour of the day can be a useful feature as energy consumption may vary depending on the time of the day.\n",
    "\n",
    "- **Day of the week**: Energy consumption may also vary depending on the day of the week.\n",
    "\n",
    "- **Month of the year**: Energy consumption may vary seasonally.\n",
    "\n",
    "- **Year**: Energy consumption may also vary depending on the year.\n",
    "\n",
    "- **Rolling statistics**: Rolling statistics are used to capture the local patterns in the data. For example, if the energy consumption has a daily pattern, then the rolling mean and standard deviation over a window of size 24 (hours) can be used to capture this pattern. By calculating the mean and standard deviation over a window of size 24, we can see if the energy consumption is higher or lower than the average consumption over the past 24 hours.\n",
    "\n",
    "- **Seasonal decomposition**: by decomposing the time series into its trend, seasonal, and residual components, we can identify the underlying patterns in the data. For example, if the energy consumption has a clear seasonal pattern, then the seasonal component will capture this pattern.\n",
    "\n",
    "- **Weather data**: Weather data can also be useful features for this problem. For example, if energy consumption is influenced by temperature, then temperature can be a useful feature. By adding temperature as a feature, we can see if energy consumption is higher or lower than the average consumption when the temperature is high or low.\n",
    "\n",
    "- **lag_1h**: This feature can be useful for capturing the temporal dependencies in the data. For example, if the energy consumption at time t is influenced by the energy consumption at time (t-1),.Therefore, I created lag feature for the last hour.\n",
    "\n",
    "- **lag_24h**: This feature can be useful for capturing the temporal dependencies in the data. Therefore, I created lag feature for the last twenty four hours.\n",
    "\n",
    "- **Rolling mean**: Rolling mean over a window of size 24 (hours).\n",
    "\n",
    "- **Rolling standard deviation**: Rolling standard deviation over a window of size 24 (hours).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcbbee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df.index.hour\n",
    "df['dayofweek'] = df.index.dayofweek\n",
    "df['month'] = df.index.month\n",
    "df['year'] = df.index.year\n",
    "df['lag_1h'] = df['Power_MWH'].shift(1)\n",
    "df['lag_24h'] = df['Power_MWH'].shift(24)\n",
    "df['rolling_mean_24h'] = df['Power_MWH'].rolling(window=24).mean()\n",
    "df['rolling_std_24h'] = df['Power_MWH'].rolling(window=24).std()\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c307f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c4951af-05f0-41d3-a05f-7c02a5fd56b6",
   "metadata": {},
   "source": [
    "# Proposing a Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a38abed",
   "metadata": {},
   "source": [
    "## Mean model: \n",
    "A mean model is a simple model that uses the mean value of the time series to predict the value of the current time step. This model can be useful as a baseline model because it makes the assumption that the energy consumption is not influenced by the previous time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b532c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# split the data into a training set and a test set\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "\n",
    "# calculate the mean model\n",
    "mean_value = train_data['Power_MWH'].mean()\n",
    "\n",
    "# predict the next hour\n",
    "y_train_pred = np.repeat(mean_value, len(train_data))\n",
    "y_test_pred = np.repeat(mean_value, len(test_data))\n",
    "\n",
    "# calculate the error\n",
    "mse_train = mean_squared_error(train_data['Power_MWH'], y_train_pred)\n",
    "mse_test = mean_squared_error(test_data['Power_MWH'], y_test_pred)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7d8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the median model\n",
    "median_value = train_data['Power_MWH'].median()\n",
    "\n",
    "# predict the next hour\n",
    "y_train_pred = np.repeat(median_value, len(train_data))\n",
    "y_test_pred = np.repeat(median_value, len(test_data))\n",
    "\n",
    "# calculate the error\n",
    "mse_train = mean_squared_error(train_data['Power_MWH'], y_train_pred)\n",
    "mse_test = mean_squared_error(test_data['Power_MWH'], y_test_pred)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8a0044",
   "metadata": {},
   "source": [
    "Since the median model has the lower MSE, the median model is the best baseline here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586e6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()\n",
    "\n",
    "# drop missing values\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbd1731-438d-4fa4-97b5-535fb4bb88e9",
   "metadata": {},
   "source": [
    "# Proposing Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c27092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "train_size = int(len(df)*0.2)\n",
    "\n",
    "train_data = df[:train_size][['hour', 'dayofweek', 'month', 'year', 'lag_1h', 'lag_24h', 'rolling_mean_24h', 'rolling_std_24h']]\n",
    "\n",
    "train_target = df[:train_size]['Power_MWH']\n",
    "# create an instance of the RandomForestRegressor class\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# fit the model on the training data\n",
    "rf.fit(train_data, train_target)\n",
    "\n",
    "# make predictions for the test data\n",
    "predictions = rf.predict(test_data.drop(columns='Power_MWH'))\n",
    "\n",
    "mse_test = mean_squared_error(test_data['Power_MWH'], predictions)\n",
    "\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d7fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the XGBRegressor class from xgboost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# create an instance of the XGBRegressor class\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# fit the model on the training data\n",
    "xgb.fit(train_data, train_target)\n",
    "\n",
    "# make predictions for the test data\n",
    "predictions = xgb.predict(test_data.drop(columns='Power_MWH'))\n",
    "\n",
    "mse_test = mean_squared_error(test_data['Power_MWH'], predictions)\n",
    "\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de013f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the SVR class from scikit-learn\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# create an instance of the SVR class\n",
    "svr = SVR()\n",
    "\n",
    "# fit the model on the training data\n",
    "svr.fit(train_data, train_target)\n",
    "\n",
    "# make predictions for the test data\n",
    "predictions = svr.predict(test_data.drop(columns='Power_MWH'))\n",
    "\n",
    "mse_test = mean_squared_error(test_data['Power_MWH'], predictions)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818bb00-f178-4350-8ea4-a9b5040adde3",
   "metadata": {},
   "source": [
    "# Evaluate and Select Final ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182b5f97",
   "metadata": {},
   "source": [
    "XGBoost is the best Machine Learning Model here since it has the least mean squared error in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
